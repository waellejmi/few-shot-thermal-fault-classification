{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3c250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715ae77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d22e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class distribution: {0: 38, 1: 31, 2: 42, 3: 31, 4: 38, 5: 34, 6: 37, 7: 35, 8: 28, 9: 25, 10: 30}\n",
      "Found 11 valid classes with at least 12 samples each\n",
      "Automatically split classes:\n",
      "  Training classes (6): Rotor-0, A&C&B10, A&B50, A&C30, Noload, A30\n",
      "  Testing classes (5): A10, Fan, A&C&B30, A&C10, A50\n",
      "Training class distribution: {0: 38, 1: 31, 4: 38, 6: 37, 9: 25, 10: 30}\n",
      "Testing class distribution: {2: 42, 3: 31, 5: 34, 7: 35, 8: 28}\n",
      "Using n_way=5 for training, n_way=5 for testing\n",
      "Valid classes for sampling: 6\n",
      "Classes with counts: [(0, 38), (1, 31), (4, 38), (6, 37), (9, 25), (10, 30)]\n",
      "Valid classes for sampling: 5\n",
      "Classes with counts: [(2, 42), (3, 31), (5, 34), (7, 35), (8, 28)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(369,\n",
       " 11,\n",
       " {'A&B50': 0,\n",
       "  'A&C&B10': 1,\n",
       "  'A&C&B30': 2,\n",
       "  'A&C10': 3,\n",
       "  'A&C30': 4,\n",
       "  'A10': 5,\n",
       "  'A30': 6,\n",
       "  'A50': 7,\n",
       "  'Fan': 8,\n",
       "  'Noload': 9,\n",
       "  'Rotor-0': 10},\n",
       " torch.Size([3, 128, 128]),\n",
       " 0,\n",
       " 5,\n",
       " 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modular.data_setup import  setup_fsl_train_test_dataloaders\n",
    "data_path = Path(\"data/\")\n",
    "\n",
    "train_loader, test_loader, fsl_dataset,(train_n_way, test_n_way) = setup_fsl_train_test_dataloaders(data_path,train_episodes=400,test_episodes=300,n_way=5,k_shot=3,q_query=9)\n",
    "\n",
    "len(fsl_dataset), len(fsl_dataset.classes), fsl_dataset.class_to_idx, fsl_dataset[0][0].shape, fsl_dataset[0][1] , train_n_way,test_n_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a28428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modular.utils import display_random_images\n",
    "# display_random_images(fsl_dataset, classes=fsl_dataset.classes, n=10, display_shape=True, seed=42)\n",
    "# #             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39ec66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modular import model_builder\n",
    "model = model_builder.Resnet18(embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a11b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "Resnet18                                      --\n",
       "├─Sequential: 1-1                             --\n",
       "│    └─Conv2d: 2-1                            (9,408)\n",
       "│    └─BatchNorm2d: 2-2                       (128)\n",
       "│    └─ReLU: 2-3                              --\n",
       "│    └─MaxPool2d: 2-4                         --\n",
       "│    └─Sequential: 2-5                        --\n",
       "│    │    └─BasicBlock: 3-1                   (73,984)\n",
       "│    │    └─BasicBlock: 3-2                   (73,984)\n",
       "│    └─Sequential: 2-6                        --\n",
       "│    │    └─BasicBlock: 3-3                   (230,144)\n",
       "│    │    └─BasicBlock: 3-4                   (295,424)\n",
       "│    └─Sequential: 2-7                        --\n",
       "│    │    └─BasicBlock: 3-5                   (919,040)\n",
       "│    │    └─BasicBlock: 3-6                   (1,180,672)\n",
       "│    └─Sequential: 2-8                        --\n",
       "│    │    └─BasicBlock: 3-7                   (3,673,088)\n",
       "│    │    └─BasicBlock: 3-8                   4,720,640\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 --\n",
       "├─Sequential: 1-2                             --\n",
       "│    └─Dropout: 2-10                          --\n",
       "│    └─Linear: 2-11                           65,664\n",
       "│    └─BatchNorm1d: 2-12                      256\n",
       "======================================================================\n",
       "Total params: 11,242,432\n",
       "Trainable params: 2,426,752\n",
       "Non-trainable params: 8,815,680\n",
       "======================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "summary(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509d12ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
       "=============================================================================================================================\n",
       "Resnet18 (Resnet18)                           [32, 3, 128, 128]    [32, 128]            --                   Partial\n",
       "├─Sequential (encoder)                        [32, 3, 128, 128]    [32, 512, 1, 1]      --                   Partial\n",
       "│    └─Conv2d (0)                             [32, 3, 128, 128]    [32, 64, 64, 64]     (9,408)              False\n",
       "│    └─BatchNorm2d (1)                        [32, 64, 64, 64]     [32, 64, 64, 64]     (128)                False\n",
       "│    └─ReLU (2)                               [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    └─MaxPool2d (3)                          [32, 64, 64, 64]     [32, 64, 32, 32]     --                   --\n",
       "│    └─Sequential (4)                         [32, 64, 32, 32]     [32, 64, 32, 32]     --                   False\n",
       "│    │    └─BasicBlock (0)                    [32, 64, 32, 32]     [32, 64, 32, 32]     (73,984)             False\n",
       "│    │    └─BasicBlock (1)                    [32, 64, 32, 32]     [32, 64, 32, 32]     (73,984)             False\n",
       "│    └─Sequential (5)                         [32, 64, 32, 32]     [32, 128, 16, 16]    --                   False\n",
       "│    │    └─BasicBlock (0)                    [32, 64, 32, 32]     [32, 128, 16, 16]    (230,144)            False\n",
       "│    │    └─BasicBlock (1)                    [32, 128, 16, 16]    [32, 128, 16, 16]    (295,424)            False\n",
       "│    └─Sequential (6)                         [32, 128, 16, 16]    [32, 256, 8, 8]      --                   False\n",
       "│    │    └─BasicBlock (0)                    [32, 128, 16, 16]    [32, 256, 8, 8]      (919,040)            False\n",
       "│    │    └─BasicBlock (1)                    [32, 256, 8, 8]      [32, 256, 8, 8]      (1,180,672)          False\n",
       "│    └─Sequential (7)                         [32, 256, 8, 8]      [32, 512, 4, 4]      --                   Partial\n",
       "│    │    └─BasicBlock (0)                    [32, 256, 8, 8]      [32, 512, 4, 4]      (3,673,088)          False\n",
       "│    │    └─BasicBlock (1)                    [32, 512, 4, 4]      [32, 512, 4, 4]      4,720,640            Partial\n",
       "│    └─AdaptiveAvgPool2d (8)                  [32, 512, 4, 4]      [32, 512, 1, 1]      --                   --\n",
       "├─Sequential (embedding)                      [32, 512]            [32, 128]            --                   True\n",
       "│    └─Dropout (0)                            [32, 512]            [32, 512]            --                   --\n",
       "│    └─Linear (1)                             [32, 512]            [32, 128]            65,664               True\n",
       "│    └─BatchNorm1d (2)                        [32, 128]            [32, 128]            256                  True\n",
       "=============================================================================================================================\n",
       "Total params: 11,242,432\n",
       "Trainable params: 2,426,752\n",
       "Non-trainable params: 8,815,680\n",
       "Total mult-adds (Units.GIGABYTES): 18.95\n",
       "=============================================================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 415.30\n",
       "Params size (MB): 44.97\n",
       "Estimated Total Size (MB): 466.56\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 128, 128), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9ed7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support set: torch.Size([15, 3, 128, 128]), torch.Size([15])\n",
      "Query set: torch.Size([45, 3, 128, 128]), torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "# Validate dataset and dataloaders\n",
    "for batch in train_loader:\n",
    "    support_images, support_labels, query_images, query_labels = batch\n",
    "    print(f\"Support set: {support_images.shape}, {support_labels.shape}\")\n",
    "    print(f\"Query set: {query_images.shape}, {query_labels.shape}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac16411",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-4,lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42a01b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modular.engine import prototypical_loss\n",
    "# # Fetch a single batch from the train_loader\n",
    "# for batch in train_loader:\n",
    "#     support_images, support_labels, query_images, query_labels = batch\n",
    "#     break  # Only take the first batch\n",
    "\n",
    "# # Move tensors to the same device as the model\n",
    "# support_images = support_images.to(device)\n",
    "# support_labels = support_labels.to(device)\n",
    "# query_images = query_images.to(device)\n",
    "# query_labels = query_labels.to(device)\n",
    "\n",
    "# # Pass the support and query images through the model\n",
    "# support_embeddings = model(support_images)\n",
    "# query_embeddings = model(query_images)\n",
    "\n",
    "# # Calculate the loss and accuracy\n",
    "# loss, accuracy = prototypical_loss(\n",
    "#     query_embeddings=query_embeddings,\n",
    "#     support_embeddings=support_embeddings,\n",
    "#     query_labels=query_labels,\n",
    "#     support_labels=support_labels,\n",
    "#     n_way=5  # Adjust based on your setup\n",
    "# )\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"Loss: {loss.item():.4f}\")\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1cd6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Counter({2: 42, 0: 38, 4: 38, 6: 37, 7: 35, 5: 34, 1: 31, 3: 31, 10: 30, 8: 28, 9: 25})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(fsl_dataset.labels)\n",
    "print(\"Class distribution:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a0d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution: Counter({0: 199})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_class_counts = Counter([fsl_dataset.labels[i] for i in train_loader.batch_sampler.labels])\n",
    "print(\"Training class distribution:\", train_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08897e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9627a45ada47098801b36c1aa530c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "Train Loss: 0.7250 | Train Acc: 0.9197 | Test Loss: 1.1216 | Test Acc: 0.9173\n",
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.4851 | Train Acc: 0.9897 | Test Loss: 1.1770 | Test Acc: 0.9379\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File best_prototypical_model.pth cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodular\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_prototype_network\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results = \u001b[43mtrain_prototype_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_way\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your setup\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust as needed\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wael\\Code\\FSL\\modular\\engine.py:218\u001b[39m, in \u001b[36mtrain_prototype_network\u001b[39m\u001b[34m(model, train_dataloader, test_dataloader, optimizer, n_way, device, epochs, patience)\u001b[39m\n\u001b[32m    216\u001b[39m     counter = \u001b[32m0\u001b[39m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest_prototypical_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNew best model saved with test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py:943\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    940\u001b[39m _check_save_filelike(f)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    944\u001b[39m         _save(\n\u001b[32m    945\u001b[39m             obj,\n\u001b[32m    946\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    949\u001b[39m             _disable_byteorder_record,\n\u001b[32m    950\u001b[39m         )\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py:810\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    809\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\serialization.py:781\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    777\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    778\u001b[39m         torch._C.PyTorchFileWriter(\u001b[38;5;28mself\u001b[39m.file_stream, _compute_crc32)\n\u001b[32m    779\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compute_crc32\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: File best_prototypical_model.pth cannot be opened."
     ]
    }
   ],
   "source": [
    "from modular.engine import train_prototype_network\n",
    "\n",
    "results = train_prototype_network(\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    test_dataloader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    n_way=5,  # Adjust based on your setup\n",
    "    epochs=10,  # Adjust as needed\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee790e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresults\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb245e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modular.utils import analyze_model_performance,plot_training_results\n",
    "analyze_model_performance(results)\n",
    "plot_training_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
